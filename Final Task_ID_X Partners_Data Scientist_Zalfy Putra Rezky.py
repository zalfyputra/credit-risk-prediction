# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GuwH619t4iJzZHHRFFIEdui_4gXHKONY

# Credit Risk Prediction

Created by: [Zalfy Putra Rezky](https://www.linkedin.com/in/zalfyputra/)

This report aims to develop machine learning models using Logistic Regression and KNN algorithms to predict credit risk based on a dataset that includes approved and rejected loan applications.

Click [here](https://rakamin-lms.s3.ap-southeast-1.amazonaws.com/vix-assets/idx-partners/loan_data_2007_2014.csv) to access the dataset and [here](https://docs.google.com/spreadsheets/d/1iT1JNOBwU4l616_rnJpo0iny7blZvNBs/edit?gid=625366020#gid=625366020) for the data dictionary.

## Data Understanding
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('loan_data_2007_2014.csv')
df.info()

"""The dataset contains 75 columns, consisting of 22 categorical columns, 53 numerical columns, and 18 inactive columns (all NULL values)."""

df.shape

df.dtypes

df.head()

df.tail()

df.describe()

"""## Exploratory Data Analysis (EDA)

Split the dataset into numerical and categorical columns
"""

# Select numerical columns
numerical_df = df.select_dtypes(exclude=['object'])

# Select categorical columns
categorical_df = df.select_dtypes(include=['object'])

# Display the numerical and categorical DataFrames
print("Numerical Columns:", numerical_df.shape[1])
print("Categorical Columns:", categorical_df.shape[1])

"""### Analyze the categorical columns"""

# Display the number of unique values in each column
categorical_df.nunique()

"""Several columns have a high number of unique values, such as `emp_title`, `url`, `desc`, and `title`. We'll only be using columns with 14 or less unique values."""

# Display columns under 14 unique values
temp = []
for col in categorical_df.columns:
    if categorical_df[col].nunique() <= 14:
        temp.append(col)

# Create a figure with subplots
fig = plt.figure(figsize=(15, 15))

# Loop through the columns
for i in range(4):
    fig.add_subplot(2, 2, i+1)
    sns.countplot(data=categorical_df, x=temp[i], palette='viridis')
    plt.xlabel(temp[i])
    plt.ylabel('Count')

# Adjust layout
plt.tight_layout()

# Display the title for the entire figure
plt.suptitle('Categorical Columns with 14 or Less Unique Values', y=1.02, fontsize=20)

# Show the plots
plt.show()

# Display and count the unique values of home_ownership column
categorical_df['home_ownership'].value_counts()

# Create a figure with subplots
fig = plt.figure(figsize=(10, 15))

# Loop through the columns
for i in range(5):
    fig.add_subplot(5, 1, i+1)
    sns.countplot(data=categorical_df, y=temp[i+4], color='teal')

# Adjust layout
plt.tight_layout()

# Display the title for the entire figure
plt.suptitle('Plot the rest of the columns', y=1.02, fontsize=15)

# Show the plots
plt.show()

"""### Analyze the numerical columns"""

# Display the number of unique values in numerical columns
numerical_df.nunique()

# Create a figure
plt.figure(figsize=(10, 6))

# Plot the distribution of loan amounts using a histogram
sns.histplot(numerical_df['loan_amnt'], bins=30, color='maroon')

# Add titles and labels
plt.title('Distribution of Loan Amounts')
plt.xlabel('Loan Amount')
plt.ylabel('Frequency')

# Show the plot
plt.show()

# Create a figure
plt.figure(figsize=(10, 6))

# Plot the distribution of loan amounts using a histogram
sns.histplot(numerical_df['installment'], bins=30, color='maroon')

# Add titles and labels
plt.title('Distribution of installment')
plt.xlabel('The monthly payment owed by the borrower if the loan originates')
plt.ylabel('Frequency')

# Show the plot
plt.show()

# Drop the columns with missing value
numerical_df = numerical_df.dropna(axis=1)

# Drop unnecessary columns
columns_to_drop = [
    'Unnamed: 0',
    'id',
    'member_id',
    'policy_code',
    'funded_amnt',
    'funded_amnt_inv',
]

# Drop the columns
numerical_df = numerical_df.drop(columns=columns_to_drop)

# Show correlation between numerical columns
plt.figure(figsize=(15, 15))
sns.heatmap(numerical_df.corr(), annot=True, cmap="crest")
plt.title('Correlation Heatmap', fontsize=20)
plt.show()

"""## Data Preparation

### Data Cleaning
"""

# Drop missing values from the categorical columns
categorical_df = categorical_df.dropna(axis=1)

# Drop missing values from the numerical columns
numerical_df = numerical_df.dropna(axis=1)

# Combine the numerical and categorical columns
df = pd.concat([numerical_df, categorical_df], axis=1)
df.isnull().sum()

# Check for duplicate rows
duplicate_rows = df.duplicated().sum()
print("Number of duplicate rows:", duplicate_rows)

"""### Feature Engineering"""

# Display and count the unique values of the loan status column
value_counts = categorical_df['loan_status'].value_counts().sort_values(ascending=False)
percentage = value_counts / value_counts.sum()
percentage = percentage.apply(lambda x: "{:.2%}".format(x))
sorted_df = categorical_df.loc[categorical_df['loan_status'].isin(value_counts.index)]

# Plot the loan status
plt.figure(figsize=(7, 5))
plt.title('Loan Status of All Customer')
sns.countplot(y="loan_status", data=sorted_df, order=value_counts.index, palette='viridis')
plt.show()

print(percentage)

"""Unique values such as `Current`, `Fully Paid`, `In Grace Period`, and `Does not meet the credit policy. Status:Fully Paid` are considered as _GOOD loans_ (with a label of 1), while the rest are _BAD loans_ (with a label of 0)."""

# Create a list of good loans
good_list = [
    'Current',
    'Fully Paid',
    'In Grace Period',
    'Does not meet the credit policy. Status:Fully Paid'
]

# Update the loan status column
df['loan_status'] = np.where(df['loan_status'].isin(good_list), 1, 0)
df['loan_status'].value_counts()

# Plot the Good Loans and Bad Loans comparison
churn_rate = df['loan_status'].value_counts()
text_props = {'color': 'gray', 'weight': 'bold'}

plt.figure(figsize=(7, 5))
plt.pie(churn_rate, labels=['Good Loans', 'Bad Loans'], autopct='%1.1f%%', colors = ['lightgreen', 'lightcoral'], explode = (0, 0.1), shadow=True, startangle=140)
plt.axis('equal')
plt.title('Comparison of Good Loans and Bad Loans', fontweight='bold')
plt.show()

# Show percentage of pymnt_plan column
df['pymnt_plan'].value_counts(normalize=True) * 100

"""The `pymnt_plan` column will be dropped because 99% of the value are `n`, making the column imbalanced."""

# Drop unnecessary columns
columns_to_drop = [
    'issue_d',
    'pymnt_plan',
    'url',
    'zip_code',
    'addr_state',
    'application_type',
]

# Drop the columns
df = df.drop(columns=columns_to_drop)
df.info()

"""### One Hot Encoding
Convert the remaining categorical columns into numerical columns.
"""

# Get object columns and create dummy variables
onehot = pd.get_dummies(df.select_dtypes(include='object'))
onehot = onehot.astype(int)
onehot.info()

"""### Feature Scaling"""

sc = StandardScaler()
scaled = pd.DataFrame(sc.fit_transform(numerical_df), columns=numerical_df.columns)
scaled.head()

"""### Finalize Dataframe"""

df = pd.concat([onehot, scaled, df[['loan_status']]], axis=1)
df.info()

"""## Data Modelling

### Data Splitting
"""

# Define the features and target
X = df.drop(columns='loan_status', axis=1)
y = df['loan_status']
y.value_counts()

# Split the data with a 80:20 ratio
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

"""### Data Training

### 1 — Logistic Regression
"""

# Define the Logistic Regression model
model = LogisticRegression()

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'penalty': ['l2', 'elasticnet'],
    'C': [1, 10],
    'solver': ['saga'],
    'l1_ratio': [0.2, 0.5]
}

# Initialize GridSearchCV with ROC AUC scoring
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)

# Fit the model on the training data
grid_search.fit(X_train, y_train)

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("Best Parameters:", best_params)
print("Best ROC AUC Score (CV):", best_score)

# Evaluate the model on the training and testing sets
best_model = grid_search.best_estimator_

y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

train_roc_auc = roc_auc_score(y_train, best_model.predict_proba(X_train)[:, 1])
test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])

print("Training Accuracy:", train_accuracy)
print("Testing Accuracy:", test_accuracy)
print("Training ROC AUC:", train_roc_auc)
print("Testing ROC AUC:", test_roc_auc)

"""### 2 — Naive Bayes"""

# Define the Naive Bayes model
model = GaussianNB()

# Fit the model on the training data
model.fit(X_train, y_train)

# Evaluate the model on the training and testing sets
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

train_roc_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])
test_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])

print("Training Accuracy:", train_accuracy)
print("Testing Accuracy:", test_accuracy)
print("Training ROC AUC:", train_roc_auc)
print("Testing ROC AUC:", test_roc_auc)

"""## Evaluation

Based on the ROC AUC scores:

1. **Logistic Regression**: Shows strong performance with a Training ROC AUC of 93.04% and Testing ROC AUC of 92.81%, indicating good generalization to unseen data.

2. **Naive Bayes**: Also performs well with a Training ROC AUC of 91.44% and Testing ROC AUC of 91.33%, suggesting it generalizes adequately to new data.

Both models shows great performance on both training and testing datasets, with similar ROC AUC scores. This suggests that they are not overfitting or underfitting significantly but are instead capturing the underlying patterns in the data effectively.
"""